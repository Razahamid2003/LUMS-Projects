{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymTO-jP4zm1V"
      },
      "source": [
        "# PA1: K-Nearest Neighbors [160 marks]\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/10/Develop-k-Nearest-Neighbors-in-Python-From-Scratch.png\">\n",
        "</center>\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In this assignment, you will be creating your second Machine Learning model from scratch: K-Nearest Neighbors.\n",
        "\n",
        "This algorithm is one of the simpler ones you will come across, but the ideas can be applied to large-scale sophisticated systems: Semantic Search and Recommendation Systems for starters.\n",
        "\n",
        "For this assignment, you will be creating your own KNN-classifier from scratch using `numpy`. You can then use this to classify images of *handwritten digits* from the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). This is the \"Hello World\" of Machine Learning. \n",
        "\n",
        "We will also be introduce a new type of nearest neighbor classifier later on. \n",
        "\n",
        "After this notebook you should be able to:\n",
        "\n",
        "- Utilize `numpy` to implement a simple KNN classifier from scratch\n",
        "\n",
        "- Understand how to setup a good Cross Validation strategy\n",
        "\n",
        "- Be able to setup simple classification tasks\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- Follow along with the notebook, filling out the necessary code where instructed.\n",
        "- <span style=\"color: red;\">Read the Submission Instructions and Plagiarism Policy in the attached PDF.</span>\n",
        "\n",
        "- <span style=\"color: red;\">Make sure to run all cells for credit.</span>\n",
        "\n",
        "- <span style=\"color: red;\">Do not remove any pre-written code.</span> Your assignment will be graded based off your output.\n",
        "\n",
        "- <span style=\"color: red;\">You must attempt all parts.</span> Do not assume that because something is for 0 marks, you can leave it - it will definitely be used in later parts.\n",
        "\n",
        "- <span style=\"color: red;\">Do not use unauthorized libraries.</span> You are not allowed to use `sklearn` in Part 1 & 3. Failure to follow these instructions will result in a serious penalty.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edrJHb_W0iT0"
      },
      "source": [
        "## Part 1: KNNs from Scratch [100 marks]\n",
        "\n",
        "Again, you are <span style=\"color: red;\">not allowed</span> to use scikit-learn or any other machine learning toolkit for this part. You have to implement your own k-NN classifier from scratch.\n",
        "\n",
        "### Importing Libraries\n",
        "All of the necessary libraries for this part have been imported for you below. You may not use any other library apart from standard Python librares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATa9_Cy01zZz",
        "outputId": "5ff773c7-56ce-49e3-af81-4f0de2b09d81"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import statistics\n",
        "import PIL\n",
        "!pip install idx2numpy\n",
        "import idx2numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MoI8-Ni2JF1"
      },
      "source": [
        "### Task 1: Extracting the dataset [12 marks]\n",
        "The MNIST dataset consists of 70,000 labeled images of handwritten digits, each of size 28 pixels by 28 pixels, yielding a total of 784 pixels per picture.\n",
        "\n",
        "Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This value ranges from 0-255\n",
        "\n",
        "The dataset can be downloaded from [here](https://www.kaggle.com/datasets/hojjatk/mnist-dataset) and is also available to in your assignment directory. The four relevant files in the folder are:\n",
        "- train-images-idx3-ubyte: training set images\n",
        "- train-labels-idx1-ubyte: training set labels\n",
        "- t10k-images-idx3-ubyte: test set images\n",
        "- t10k-labels-idx1-ubyte: test set labels\n",
        "\n",
        "The dataset has been split with 60,000 images in the train set, and the remaning 10,000 images in the test set.\n",
        "\n",
        "Your very first task is to to convert this dataset into a pandas dataframe.\n",
        "\n",
        "Hint: *use the idx2numpy package to convert the dataset to a multidimensional numpy array. The documentation can be visited [here](https://pypi.org/project/idx2numpy/). The resulting array then has to be flattened.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLxks7QI9nd6",
        "outputId": "25159f92-348f-4a3b-9ed4-6a39dcb7a8ec"
      },
      "outputs": [],
      "source": [
        "#Input the file paths\n",
        "train_images_path = \n",
        "train_labels_path = \n",
        "test_images_path = \n",
        "test_labels_path = \n",
        "\n",
        "#TODO: Convert the idx files to numpy [4 marks]\n",
        "\n",
        "#TODO: Print the shape of the multidimensional array for both train and test set [1 mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av8yA_kTEqXM",
        "outputId": "90185fc2-b1f3-4573-e19c-3342c2bb785c"
      },
      "outputs": [],
      "source": [
        "#TODO: Flatten the array, append the labels and print the shape again [5 mark]\n",
        "#The shape of your train set should be (60000, 785), and test set should be (10000, 785)\n",
        "#IMPORTANT: If your shapes are not matching, dont attempt the rest of the assignment unless you get it right.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_59QdLKPXVe"
      },
      "source": [
        "QUESTION: What does each row of the dataset represents? [2 marks]\n",
        "\n",
        "ANSWER: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKWPZTwoQ6EN"
      },
      "source": [
        "### Task 2: Visualizing and preprocessing the dataset [12 marks]\n",
        "\n",
        "Now that we have a dataset to work with, we need to preprocess it further, before we pass it through our classifier. In this step, we will be seperating out the labels from the inputs, and attempt to standardize or normalize our dataset.\n",
        "\n",
        "Note that the standardization of a variable $x$ refers to:\n",
        "$$\n",
        "x' = \\frac{x - μ}{σ}\n",
        "$$\n",
        "\n",
        "where $μ$ is the mean of the variable and $σ$ is the standard deviation.\n",
        "\n",
        "On the other hand, variable normalization usually involves scaling the data to a specific range.\n",
        "\n",
        "You can read more about this [here](https://www.simplilearn.com/normalization-vs-standardization-article).\n",
        "\n",
        "After you've loaded and split the dataset, let's display some images. You can reshape these 784 values for each image, into a `28x28` array, then use either `matplotlib` or `PIL` to display the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwU-waffL_UD",
        "outputId": "c5beeee1-c694-4379-f8d2-913a89f143aa"
      },
      "outputs": [],
      "source": [
        "#TODO: Extract labels and features [2 marks]\n",
        "train_x = \n",
        "train_y = \n",
        "test_x = \n",
        "test_y = \n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L-Ydx4SZWvoq",
        "outputId": "663e0be9-ec74-4ef9-86a4-6fec6d980149"
      },
      "outputs": [],
      "source": [
        "#TODO: Implement a function to display image. The label should be used as a title [6 marks]\n",
        "#      Randomly pick 5 rows from the training dataset and display their images\n",
        "\n",
        "def display_image(features, label):\n",
        "  '''\n",
        "    Takes a 1D numpy array, reshapes to a 28x28 array and displays the image\n",
        "  '''\n",
        "\n",
        "  return None\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhDHZZjKbYQn"
      },
      "outputs": [],
      "source": [
        "#TODO: normalize the data so that it falls in the [0, 1] range. [2 marks]\n",
        "#      Hint: the max value of each pixel is 255\n",
        "\n",
        "def normalize(data):\n",
        "  '''\n",
        "    scales the data to the range [0, 1]\n",
        "  '''\n",
        "\n",
        "  return None\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI5YcIk5R1aq"
      },
      "source": [
        "QUESTION: With the variable standardization formula shown above in the description, is this technique feasible in this dataset? Explain in detail. [2 marks]\n",
        "\n",
        "ANSWER: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lrUL-PdesE-"
      },
      "source": [
        "### Task 3: Implementing k-NN Classifier [20 marks]\n",
        "\n",
        "Now you can create your own k-NN classifier. You can use the following steps as a guide:\n",
        "\n",
        "1. For a test data point, find its distance from all training instances.\n",
        "\n",
        "2. Sort the calculated distances in ascending order based on distance values.\n",
        "\n",
        "3. Choose k training samples with minimum distances from the test data point.\n",
        "\n",
        "4. Return the *most frequent* class of these samples.\n",
        "\n",
        "For values of `k` where a tie occurs, you need to break the tie by backing off to the `k-1` value. In case there is still a tie, you will continue decreasing `k` until there is a clear winner.\n",
        "\n",
        "#### Important\n",
        "**Note:** Your function should work with *Euclidean* distance as well as *Manhattan* distance. Pass the distance metric as a parameter in the k-NN classifier function. Your function should also let one specify the value of `k`.\n",
        "\n",
        "**Note:** Your approach should be vectorized. Failure to implement a vectorization-based method to calculate distances will result in significant loss of marks. You can read up vectorization [here](https://towardsdatascience.com/vectorization-implementation-in-machine-learning-ca652920c55d)\n",
        "\n",
        "#### Distance functions\n",
        "\n",
        "Implement separate functions for the Euclidean and Manhattan distances. Formulas for both are given below.\n",
        "\n",
        "$$\n",
        "d_{\\text{Euclidean}}(\\vec{p},\\vec{q}) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + (p_3 - q_3)^2 + ... + (p_n - q_n)^2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "d_{\\text{Manhattan}}(\\vec{p},\\vec{q}) = |(p_1 - q_1)| + |(p_2 - q_2)| + |(p_3 - q_3)| + ... + |(p_n - q_n)|\n",
        "$$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following method functions:\n",
        "- `euclidean_distance`\n",
        "- `manhattan_distance`\n",
        "- `fit`\n",
        "- `get_neighbors`\n",
        "- `predict`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g5CHnmWfTZT"
      },
      "outputs": [],
      "source": [
        "#TODO: Complete the class below\n",
        "class KNN:\n",
        "\n",
        "  def __init__(self, k):\n",
        "    #DO NOT EDIT !#\n",
        "    '''\n",
        "      Initializes the class\n",
        "    '''\n",
        "\n",
        "    self.k = k\n",
        "    self.train_x = None\n",
        "    self.train_y = None\n",
        "\n",
        "  def euclidean_distance(self, x1, x2): #[4 marks]\n",
        "    #USE NUMPY METHODS\n",
        "    '''\n",
        "      Takes two numpy arrays and calculates the euclidean distance between them\n",
        "    '''\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  def manhattan_distance(self, x1, x2): #[4 marks]\n",
        "    #USE NUMPY METHODS\n",
        "    '''\n",
        "      Takes two numpy arrays and calculates the manhattan distance between them\n",
        "    '''\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  def fit(self, train_x, train_y): #[1 mark]\n",
        "    '''\n",
        "      Stores the training dataset\n",
        "    '''\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  def get_neighbors(self, new_point, distancefunc): #[6 marks]\n",
        "    '''\n",
        "      Takes a new point and returns the k nearest neighbors\n",
        "      Hint: Sort the distances by their index to get the labels easily\n",
        "    '''\n",
        "    return None\n",
        "    \n",
        "\n",
        "  def predict(self, test_x, distancefunc): #[5 marks]\n",
        "    '''\n",
        "      Takes a test set and returns the predicted labels\n",
        "    '''\n",
        "    return None\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bhfDOcdsseW"
      },
      "source": [
        "### Task 4: Evaluation [24 marks]\n",
        "\n",
        "Now that you've created a model and \"trained\" it, you can move on to the Evaluation phase.\n",
        "\n",
        "- We will be implementing an `evaluate` function that computes the Confusion Matrix, Accuracy, and Macro-Average F1 score of your classifier. You can use multiple helper functions to calculate the individual metrics.\n",
        "\n",
        "- The function should take as input the predicted labels and the true labels. This will be built in steps: its easier to create a Confusion Matrix, then calculate things like the Precision, Recall and F1 from it.\n",
        "\n",
        "- We will also implement a function that displays our confusion matrix as a heatmap annotated with the data values.\n",
        "- The axes should be properly labelled and the colormap used needs to be shown next to the heatmap.\n",
        "- You can have a look at some examples of heatmaps [here](https://seaborn.pydata.org/generated/seaborn.heatmap.html). (You don't have to use the seaborn libray, but it has some pretty colour palettes to choose from.)\n",
        "\n",
        "We recommend that you do not use hard coding in this function.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following functions:\n",
        "\n",
        "- `accuracy`\n",
        "- `make_confusion_matrix`\n",
        "- `make_heat_map`\n",
        "- `precision`\n",
        "- `recall`\n",
        "- `f1_score`\n",
        "- `macro_average_f1`\n",
        "- `evaluate`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z4zZc9nuUIK"
      },
      "outputs": [],
      "source": [
        "def accuracy(predicted_labels, true_labels): #[2 marks]\n",
        "  '''\n",
        "    Takes the predicted labels and the true labels and returns the accuracy\n",
        "  '''\n",
        "  \n",
        "  return None\n",
        "\n",
        "\n",
        "def make_confusion_matrix(predicted_labels, true_labels): #[6 marks]\n",
        "  '''\n",
        "    Takes the predicted labels and the true labels and returns the confusion matrix\n",
        "    Hint: You can create a helper function which calculates each row of the confusion matrix\n",
        "  '''\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "def make_heat_map(confusion_matrix, title): #[4 marks]\n",
        "  '''\n",
        "    Takes the confusion matrix and plots it as a heatmap\n",
        "  '''\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "def precision(confusion_matrix, class_label): #[2 marks]\n",
        "  '''\n",
        "    Takes the confusion matrix and a label and returns the precision\n",
        "  '''\n",
        "  \n",
        "  return None\n",
        "\n",
        "def recall(confusion_matrix, class_label): #[2 marks]\n",
        "  '''\n",
        "    Takes the confusion matrix and a label and returns the recall\n",
        "  '''\n",
        "\n",
        "  return None\n",
        "\n",
        "def f1_score(precision, recall): #[2 marks]\n",
        "  '''\n",
        "    Takes the precision and recall and returns the f1 score\n",
        "  '''\n",
        "\n",
        "  return None\n",
        "\n",
        "def macro_average_f1(confusion_matrix): #[4 marks]\n",
        "  '''\n",
        "    Calculates the macro-average F1 score from a provided confusion matrix, over all classes\n",
        "  '''\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "def evaluate(predicted_labels, true_labels): #[2 marks]\n",
        "  '''\n",
        "    Displays and returns a nicely formatted report with accuracy, macro-average f1 score, and confusion matrix\n",
        "  '''\n",
        "  \n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ffy_t6Ln7SP"
      },
      "source": [
        "### Task 5: k-fold Cross Validation [20 marks]\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://global.discourse-cdn.com/dlai/original/3X/a/3/a3ed2de61c2b4fa00f1b7e939753e1a7e181afb0.png\">\n",
        "</center>\n",
        "\n",
        "Now with the basics done, you can move on to the next step: k-fold Cross Validation. This is a more robust way of evaluating your model since it uses all the data for training and testing (effectively giving you `k` chances to verify the generalizability of your model).\n",
        "\n",
        "Now, implement a function that performs `k`-fold cross-validation on the training data for a specified value of `k`.\n",
        "\n",
        "In Cross Validation, you divide the dataset into `k` parts. `k-1` parts will be used for training and `1` part will be used for validation. You will repeat this process `k` times, each time using a different part for validation. You will then average the results of each fold to get the final result. Take a look at the image above for a better understanding.\n",
        "\n",
        "The function should return **predictions** for the **entire training data** (size of list/array should be equal to the size of the dataset). This is the result of appending the predicted labels for each validation-train split into a single list/array. Make sure the order of the predicted labels matches the order of the training dataset, so that they may directly be passed to your `evaluate` function together with the actual labels.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following functions:\n",
        "\n",
        "- `k_fold_split`\n",
        "- `k_fold_cross_validation`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qIMB-GOo3b4"
      },
      "outputs": [],
      "source": [
        "def k_fold_split(num_folds, cv_no, train_x, train_y): #[3 marks]\n",
        "    '''\n",
        "    Creates the train and test splits based off the value of k\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mum_folds : int\n",
        "        Number of folds\n",
        "    cv_no : int\n",
        "        The current fold number\n",
        "    train_x : nparray\n",
        "        The features\n",
        "    train_y : nparray\n",
        "        The labels\n",
        "    '''\n",
        "\n",
        "    return None\n",
        "\n",
        "def k_fold_cross_validation(num_folds, k, train_x, train_y, distanceFunction): #[3 marks]\n",
        "    \"\"\"\n",
        "    Returns the predictions for all the data points in the dataset using k-fold cross validation\n",
        "\n",
        "    num_folds: int\n",
        "      Number of folds\n",
        "    k: int\n",
        "      Number of neighbours to consider (hyperparameter)\n",
        "    train_x : nparray\n",
        "        The features\n",
        "    train_y : nparray\n",
        "        The labels\n",
        "    distanceFunction : str\n",
        "        Distance metric specified (manhattan / euclidean)\n",
        "    \"\"\"\n",
        "    \n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sn6lArVqO4y"
      },
      "source": [
        "Now run your cross-validation function on the training data using `5-fold cross validation` for the values of `k = [1, 2, 3, 4, 5]`.\n",
        "\n",
        "Do this for both the Euclidean distance and the  Manhattan distance for each value of `k`.\n",
        "\n",
        "Also run your evaluation function for each value of `k` (for both distance metrics) and print out the classification accuracy and F1 score.\n",
        "\n",
        "**Note: Save your evaluation stats for plotting later**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRsvTS3ftete"
      },
      "outputs": [],
      "source": [
        "#Save scores here for plotting later\n",
        "accuracy_list_euclidean = []\n",
        "f1_list_euclidean = []\n",
        "accuracy_list_manhattan = []\n",
        "f1_list_manhattan = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBqUPkZZqLvh"
      },
      "outputs": [],
      "source": [
        "#[6 marks]\n",
        "# TODO: Perform cross-validation for both distances and run your evaluation function for each K, printing the accuracy and macro-average F1 score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShGems2Ar9jK"
      },
      "source": [
        "Next, present the results as a graph with `k` values on the x-axis and classification accuracy on the y-axis. Use a single plot to compare the two versions of the classifier (one using Euclidean and the other using Manhattan distance metric).\n",
        "\n",
        "Make another graph but with the F1-score on the y-axis this time. The graphs should be properly labeled on axes, with a title, and a legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW4yrC1TsU1x"
      },
      "outputs": [],
      "source": [
        "#[8 marks]\n",
        "#TODO: Plot a graph with k values on the x-axis and classification accuracy on the y-axis (both distances on one plot).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzYhKiKtsbWV"
      },
      "outputs": [],
      "source": [
        "#TODO: Plot a graph with k values on the x-axis and F1-score on the y-axis (both distances on one plot). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpPyGROIy1OW"
      },
      "source": [
        "### Task 6: Prediction [12 marks]\n",
        "\n",
        "Finally, use the best value of `k` for both distance metrics and run it on the test dataset.\n",
        "\n",
        "Find the confusion matrix, classification accuracy and F1 score and print them.\n",
        "\n",
        "The confusion matrix must be displayed as a heatmap annotated with the data values. The axes should be properly labelled and the colormap used needs to be shown next to the heatmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT5GuCWzzMKk"
      },
      "outputs": [],
      "source": [
        "#TODO: Test with the best K for euclidean distance [6 marks]\n",
        "best_k =\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-yOuhIVzaGh"
      },
      "outputs": [],
      "source": [
        "#TODO: Test with the best K for Manhattan distance [6 marks]\n",
        "best_k =\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW7v8Q8wzIqq"
      },
      "source": [
        "## Part 2: KNN using Scikit-Learn [10 marks]\n",
        "\n",
        "In this part, you have to use [scikit-learn's k-NN implementation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to train and test your classifier on the dataset used in Part 1. Repeat the tasks you have done in Part 1 but this time using scikit-learn.\n",
        "\n",
        "- Use the best value of `k` from part 1 for both manhattan and euclidean distance. You don't need to perform k-fold cross validation this time\n",
        "\n",
        "- Use scikit-learn's [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function to calculate the accuracy, the [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to calculate macro-average F1 score,\n",
        "and the [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function to calculate confusion matrix from the predicted labels.\n",
        "\n",
        "**NOTE: Use the preprocessed dataset from Part 1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "612kIhp50eQd",
        "outputId": "ceac748b-372a-49a8-d8fe-990c3dd00a36"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn==1.4.2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "WilX3c8NCSK8",
        "outputId": "cd1c1f79-66cf-4284-ea89-5ba54dfd868f"
      },
      "outputs": [],
      "source": [
        "#TODO: Using the best value of K from part one, train and test a KNN classifier with Euclidean distance [5 marks]\n",
        "#      Display accuracy, macro f1 score, and a heat map of confusion matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "o4xjsrrIFDbx",
        "outputId": "d5134163-dd5b-4b16-8cfb-cc411e2d20cd"
      },
      "outputs": [],
      "source": [
        "#TODO: Using the best value of K from part one, train and test a KNN classifier with Manhattan distance [5 marks]\n",
        "#      Display accuracy, macro f1 score, and a heat map of confusion matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssfOBj4u9lGd"
      },
      "source": [
        "## Part 3: Radius nearest neighbors [50 marks]\n",
        "<center>\n",
        "    <img src=\"https://media.springernature.com/m312/springer-static/image/art%3A10.1134%2FS1054661820030268/MediaObjects/11493_2020_6090_Fig5_HTML.gif?\">\n",
        "</center>\n",
        "\n",
        "Radius Neighbors Classifier is an extension to the k-nearest neighbors algorithm that makes predictions using all examples in the radius of a new example rather than the k-closest neighbors. Read more about this neighbor-based classifier [here](https://machinelearningmastery.com/radius-neighbors-classifier-algorithm-with-python/#:~:text=Radius%20Neighbors%20Classifier%20is%20a,than%20the%20k%2Dclosest%20neighbors.).\n",
        "\n",
        "The Radius Neighbors Classifier is similar to KNN in respect that its training involves storing the entire training dataset. However, instead of basing decisions on k-nearest neighbors, the Radius Neighbors Classifier locates all examples in the training dataset that are within a given radius of the new example to make a prediction.\n",
        "\n",
        "For this part, we will be using the [Breast Cancer Dataset](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IveES8NPZzxe"
      },
      "source": [
        "###Task 1: Data Loading and Preprocessing [12 marks]\n",
        "\n",
        "The breast cancer dataset comprises of 569 rows and 32 columns. Your task is to design a r-NN classifier that is able to classify breast tumors into malignant (cancerous) or benign (non cancerous).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "2ocsR8pCaOYT",
        "outputId": "52581abc-ef28-4380-96d7-c2e29d451fa0"
      },
      "outputs": [],
      "source": [
        "#TODO: Read the dataset into a pandas dataframe, display its shape, and its first 5 rows [3 marks]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Fy7_DfM6ag8Z",
        "outputId": "43a03b75-7400-4c8e-f639-ec6489dd2eb9"
      },
      "outputs": [],
      "source": [
        "#TODO: Drop the id column [1 mark]\n",
        "\n",
        "\n",
        "#TODO: Replace the dataset labels with their numeric counterparts: M->1, B->0 [1 mark]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmSBxuBudcKt",
        "outputId": "0b17b068-9090-406a-8294-164844e673ec"
      },
      "outputs": [],
      "source": [
        "#TODO: Randomly sample 80% of the dataset for train dataset and retain the remaining 20% for test dataset [2 marks]\n",
        "\n",
        "\n",
        "#TODO: split features from labels [1 mark]\n",
        "train_x = \n",
        "train_y = \n",
        "test_x = \n",
        "test_y = \n",
        "#Print the shape of train_x, train_y, test_x, test_y\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRvDxBuZegoY"
      },
      "outputs": [],
      "source": [
        "#TODO: Convert your dataframes to numpy array [1 mark]\n",
        "\n",
        "\n",
        "#TODO: standardize your features in test and train sets [3 mark]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awR-2YPCC-Cg"
      },
      "source": [
        "### Task 2: Implementing r-NN Classifier [10 marks]\n",
        "\n",
        "You are now fully equipped to create your own radius nearest neighbor classifier. You can use the following steps as a guide:\n",
        "\n",
        "- For a test data point, find its distance from all training instances.\n",
        "\n",
        "- Sort the calculated distances in ascending order based on distance values.\n",
        "\n",
        "- Choose all of the training examples that are within the radius `r`\n",
        "\n",
        "- Return the most frequent class of these samples.\n",
        "\n",
        "**Note:** Sometimes for the radius `r`, it is possible that you will not have any training examples in the given radius for some test data points. In this case, simply return the **majority class** of the dataset.\n",
        "\n",
        "On the other hand, if there is a tie, you can use a similar strategy as before. Remove the furthest training example from your choosen neighbors to take a vote.\n",
        "\n",
        "You can reuse parts of your code from the KNN class\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following methods:\n",
        "- `euclidean_distance`\n",
        "- `manhattan_distance`\n",
        "- `fit`                \n",
        "- `get_neighbors`      \n",
        "- `predict`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brauku9mJRRs"
      },
      "outputs": [],
      "source": [
        "#TODO: Complete the class below\n",
        "class RNN:\n",
        "\n",
        "  def __init__(self, r):\n",
        "    #DO NOT EDIT !#\n",
        "    '''\n",
        "      Initializes the class\n",
        "    '''\n",
        "\n",
        "    self.r = r\n",
        "    self.train_x = None\n",
        "    self.train_y = None\n",
        "\n",
        "  def euclidean_distance(self, x1, x2): #[1 mark]\n",
        "    #USE NUMPY METHODS\n",
        "    '''\n",
        "      Takes two numpy arrays and calculates the euclidean distance between them\n",
        "    '''\n",
        "\n",
        "    return None\n",
        "\n",
        "  def manhattan_distance(self, x1, x2): #[1 mark]\n",
        "    #USE NUMPY METHODS\n",
        "    '''\n",
        "      Takes two numpy arrays and calculates the manhattan distance between them\n",
        "    '''\n",
        "\n",
        "    return None\n",
        "\n",
        "  def fit(self, train_x, train_y): #[1 mark]\n",
        "    '''\n",
        "      Stores the training dataset\n",
        "    '''\n",
        "    self.train_x = \n",
        "    self.train_y = \n",
        "\n",
        "  def get_neighbors(self, new_point, distancefunc): #[3 mark]\n",
        "    '''\n",
        "      Takes a new point and returns the nearest neighbors within the radius r\n",
        "      Hint: Sort the distances by their index to get the labels easily\n",
        "    '''\n",
        "    \n",
        "    return None\n",
        "\n",
        "  def predict(self, test_x, distancefunc): #[4 mark]\n",
        "    '''\n",
        "      Takes a test set and returns the predicted labels\n",
        "    '''\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K3hiy6nK32j"
      },
      "source": [
        "### Task 3: k-fold Cross Validation [18 marks]\n",
        "\n",
        "In this part, for **euclidean distance**, uniformally sample **20** different values of `r` from the range `3.5-5.5`. Use these values of `r` for 5-fold cross validation using the functions you implemented in part 1.\n",
        "\n",
        "For **manhattan distance** uniformally sample **20** different values of `r` from the range `15.5-17.5`. Use these values of `r` for 5-fold cross validation using the functions you implemented in part 1.\n",
        "\n",
        "Again, for each `r`, conduct the cross validation for both distances and report accuracy and macro-f1 score for each `r` and distance. You can use sklearn evaluation metrics to report the results\n",
        "\n",
        "**Store these results for plotting later.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPufnjftWn-8"
      },
      "outputs": [],
      "source": [
        "#TODO: Redefine your k-fold cross validation functions to account for the r-NN classifier [2 marks]\n",
        "\n",
        "def k_fold_cross_validation_rnn(num_folds, r, train_x, train_y, distanceFunction):\n",
        "  \"\"\"\n",
        "    Returns the predictions for all the data points in the dataset using k-fold cross validation\n",
        "\n",
        "    num_folds: int\n",
        "      Number of folds\n",
        "    r: float\n",
        "      Radius of neighbours to consider (hyperparameter)\n",
        "    train_x: np array\n",
        "      The dataset features to be used\n",
        "    test_x: np array\n",
        "      The dataset labels to be used\n",
        "    distancefunc: str\n",
        "      The distance function to be used\n",
        "    \"\"\"\n",
        "\n",
        "return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5RCJgHaYnI9"
      },
      "outputs": [],
      "source": [
        "#TODO: Unformally sample 20 values of r in the range mentioned above for both distances. [2 marks]\n",
        "#      Hint: Sort the sampled values for a nice graph later on\n",
        "\n",
        "#list for storing results\n",
        "accuracy_list_euclidean = []\n",
        "f1_list_euclidean = []\n",
        "accuracy_list_manhattan = []\n",
        "f1_list_manhattan = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAcM5__7MBM5",
        "outputId": "4b9913c3-d9fe-40a1-de1a-4da89a3c0703"
      },
      "outputs": [],
      "source": [
        "# TODO: Perform cross validation and report the results (accuracy and macro f1) for euclidean distances for each r [3 marks]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZLFWNMZYkwu"
      },
      "outputs": [],
      "source": [
        "# TODO: Perform cross validation and report the results for manhattan distances for each r [3 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "XaLL7Wz_MMW1",
        "outputId": "d04b2d80-ddab-4c13-910c-75cb539cd30c"
      },
      "outputs": [],
      "source": [
        "#TODO: Plot the scores for euclidean distance [3 marks]\n",
        "#      Report the values of r on the x-axis, and corresponding accuracy and f1 score on the y-axis\n",
        "#      Hint: This plot does not have the same structure as that of part 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx8ekvkBMqw8"
      },
      "outputs": [],
      "source": [
        "#TODO: Make a similar plot for Manhattan distance as well with r on x-axis and accuracy and f1 on y-axis. Make sure your plots are properly labelled [3 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0LwjRINMt5m"
      },
      "source": [
        "QUESTION: Discuss how the value of `r` relates to overfitting and underfitting. [2 marks]\n",
        "\n",
        "\n",
        "Answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmeH2feNM_TV"
      },
      "source": [
        "### Task 4: Prediction [10 marks]\n",
        "\n",
        "Finally, use the best value of `r` for both distance metrics and run it on the test dataset. Make sure you do not harcode values of `r` in this part.\n",
        "\n",
        "Find the confusion matrix, classification accuracy and macro F1 score and print them. You can use Sklearn's evaluation metrics in this part as well.\n",
        "\n",
        "The confusion matrix must be displayed as a heatmap annotated with the data values. The axes should be properly labelled and the colormap used needs to be shown next to the heatmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWc1gm3bNQcv",
        "outputId": "e7123136-0729-4e1d-a422-9d32fb2f6528"
      },
      "outputs": [],
      "source": [
        "#TODO: Test with the best r for euclidean distance [4 marks]\n",
        "\n",
        "best_r ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a5JZeYpNWGT",
        "outputId": "fdd443e8-7f96-46cb-ada4-bc63a6108783"
      },
      "outputs": [],
      "source": [
        "#TODO: Test with the best r for euclidean distance [4 marks]\n",
        "\n",
        "best_r ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7hS_VJKNYh1"
      },
      "source": [
        "QUESTION: Explain why rNN classifier would have been a poor choice for the MNIST dataset. Discuss with respect to curse of dimentionality. [2 marks]\n",
        "\n",
        "Answer:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.11.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "ff4b1fca65a764b45acb559e482afe389d289dd599b9f8c5fd12ff5c2ea46a65"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
