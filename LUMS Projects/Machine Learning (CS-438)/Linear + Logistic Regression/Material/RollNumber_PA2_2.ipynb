{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31be63a5-d870-4a2c-986b-133f475fe22c",
   "metadata": {},
   "source": [
    "# Problem Background: The Great Migration\n",
    "\n",
    "In our ongoing efforts to ensure the safety of the migration to Earth Junior, we have developed a linear regression model that produces a human-zombie score ranging from 0 to 100. This score is designed to assess the likelihood of individuals being human or zombie based on various features collected during screening.\n",
    "\n",
    "To enhance our security measures, the spaceship station has deployed a specialized automated barrier system that utilizes the human-zombie scores to classify individuals into three distinct categories:\n",
    "\n",
    "- **Class 0: Score Range 0-33**: **Most Likely Human**  \n",
    "  Individuals in this range will be directed straight to the spaceship for immediate boarding.\n",
    "\n",
    "- **Class 1: Score Range 33-66**: **Need Further Tests**  \n",
    "  Those with scores in this range will be redirected to a testing facility for additional examinations to confirm their identity. They will be quarantined for a two-week observational period to ensure they do not pose a risk.\n",
    "\n",
    "- **Class 3: Score Range 66-100**: **Most Likely Zombies**  \n",
    "  Those scoring in this highest range will be denied entry to the spaceship, as they are deemed a significant threat to the safety of the remaining human population.\n",
    "\n",
    "This classification system aims to maximize the chances of a successful migration while ensuring that the risk of zombie infiltration is minimized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03373c37",
   "metadata": {
    "id": "03373c37"
   },
   "source": [
    "# Programming Assignment 2: Task 2 -- Logistic Regression  [80 Marks]\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this task, you will be Logistic Regression models for the provided dataset from scratch. A description of the problem statement is given at the start of part. It is important that you display the output where asked. In case of no outputs, you will get a 0 for that part.\n",
    "\n",
    "After this notebook you should be able to:\n",
    "\n",
    "- Implement a classifier using Logistic Regression.\n",
    "\n",
    "- Create a Logistic Regression model using simple `numpy`.\n",
    "\n",
    "Have fun!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Follow along with the notebook, filling out the necessary code where instructed.\n",
    "\n",
    "- <span style=\"color: red;\">Read the Submission Instructions and Plagiarism Policy in the attached PDF.</span>\n",
    "\n",
    "- <span style=\"color: red;\">Make sure to run all cells for credit.</span>\n",
    "\n",
    "- <span style=\"color: red;\">Do not remove any pre-written code.</span> We will be using the `print` statements to grade your assignment.\n",
    "\n",
    "- <span style=\"color: red;\">You must attempt all parts.</span> Do not assume that because something is for 0 marks, you can leave it - it will definitely be used in later parts.\n",
    "\n",
    "- <span style=\"color: red;\">Do not use unauthorized libraries.</span> You are not allowed to use `sklearn` in Part A of both tasks. Failure to follow these instructions will result in a serious penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9dcc17-bd78-42a6-bf52-044df6c543bf",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img src = \"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*RElrybCZ4WPsUfRwDl7fqA.png\">\n",
    "</center>\n",
    "\n",
    "One vs All (OvA) is a common technique to extend binary classifiers, like logistic regression, to handle multiclass classification tasks. For each class in the dataset, a logistic regression model is trained to distinguish that class from all other classes. For instance, for a `m` class classification, we will have `m` logistic regression classifiers in our pipeline. When making a prediction, each model outputs a probability that the instance belongs to its target class. The class with the highest probability across all models is chosen as the final prediction.\n",
    "\n",
    "In this part, we will be going over how to implement a Multiclass Logistic Regression (OvA) model from scratch. For a review of this concept, you can go over the course slides or go over this [resource](https://www.cs.rice.edu/~as143/COMP642_Spring22/Scribes/Lect5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4e279-4c7c-4b6c-a208-e5b607b41863",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e61d1099-bde3-45aa-8d1d-5bfa6b169ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5216e2a",
   "metadata": {
    "id": "b5216e2a",
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "#### Dataset\n",
    "\n",
    "You will use the same dataset as Part A.\n",
    "\n",
    "Load the Dataset and other necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec0d6e",
   "metadata": {
    "id": "c6ec0d6e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66384c63",
   "metadata": {
    "id": "66384c63"
   },
   "source": [
    "# Preprocessing   [20 Marks]\n",
    "\n",
    "In this step, you will need to make several changes to the dataset before we can proceed with the analysis. Follow the guidelines below:\n",
    "\n",
    "1. **Transform Labels**:  \n",
    "   Convert the labels from continuous scores to categorical labels based on the class descriptions provided earlier.  \n",
    "   This transformation is crucial for training the classifier effectively. **[5 Points]**\n",
    "\n",
    "2. **Perform Train-Test Split**:  \n",
    "   Split the dataset into training and testing sets (8:2), and then check the sizes of both.  \n",
    "   This step ensures that you have the right distribution of data for training and evaluation. **[5 Points]**\n",
    "\n",
    "3. **Normalize Data**:  \n",
    "   Utilize the `Scaler` class that you created in Part 1 to normalize the features of the dataset. **[10 Points]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d8fe2f33",
   "metadata": {
    "id": "d8fe2f33"
   },
   "outputs": [],
   "source": [
    "# Transform Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b474ff",
   "metadata": {
    "id": "43b474ff"
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b4cc36c8-2ab1-4a0f-b599-2bc297084cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331017de",
   "metadata": {
    "id": "331017de"
   },
   "source": [
    "## Part A: Implementation from Scratch  [25 Marks]\n",
    "\n",
    "Create a class, and implement the functionality described below to create a fully fledged **Regularized Logistic Regression model.**\n",
    "\n",
    "* `sigmoid(x)`: This is the non-linear \"activation\" function that differentiates Logistic from plain-old Linear Regression. Refer to the formula from the slides. [5 Points]\n",
    "\n",
    "* `cross_entropy_loss(y_true, y_pred)`: This is the loss function that will help you calculate the gradients for updating your model. Note that this is a Binary Classification task so you can use the Binary Cross Entropy function mentioned in the slides. [5 Points]\n",
    "\n",
    "* `fit(x_train, y_train)`: This will be where you implement the Gradient Descent algorithm again, keeping in mind the differences between Linear and Logistic Regression. [5 points]\n",
    "\n",
    "* `predict(x_test)`: predict whether the label is 0 or 1 for test reviews using learned logistic regression (use the decision threshold of 0.5) **Note: you need to return the probability and the predicted label from this function** [5 Points]\n",
    "\n",
    "* `evaluate(y_true, y_pred)` function that calculates classification accuracy, F1 Score and confusion matrix. [5 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "794011ae",
   "metadata": {
    "id": "794011ae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b787df1",
   "metadata": {
    "id": "6b787df1"
   },
   "source": [
    "# Implement One vs All Classification  [10 marks]\n",
    "\n",
    "You need to build four classifiers, one for each class, and perform the following steps for each:\n",
    "\n",
    "1. Create a plot with the number of iterations/epochs on the x-axis and training/validation loss on the y-axis for the evaluation dataset that we separated previously.\n",
    "\n",
    "2. Tune the hyperparameters, i.e., learning rate and number of epochs, to minimize the validation loss.\n",
    "\n",
    "**Please note that the correctness of the functions you created previously depends on the plot. The curve should show a constant dip, eventually reaching a plateau.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c55a386",
   "metadata": {
    "id": "2c55a386",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-vs-Rest Classifiers\n",
    "classifiers = {}\n",
    "losses = {}  # To store losses for each classifier\n",
    "\n",
    "for i in range(3):\n",
    "    y_binary = (train_labels == i).astype(int)  # Current positive class, use this while fitting to train data\n",
    "    classifiers[i] = None       # declare your logistic regression model here \n",
    "    cost = None                 # fit on your training data and store the cost. You will need to pass y_binary along with the train data\n",
    "    losses[i] = cost            # Save the cost values for plotting\n",
    "\n",
    "# Plot training loss for each classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434bf54",
   "metadata": {
    "id": "f434bf54"
   },
   "source": [
    "# Evaluate  [15 Marks]\n",
    "\n",
    "It's time to run your logistic regression model on the test dataset!\n",
    "\n",
    "- Report the accuracy, F1 score and confusion matrix for each binary classifier [10 Points]\n",
    "- Perform multiclass evaluation and report macro F1, accuracy and confusion matrix [5 marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4b2d1d5a",
   "metadata": {
    "id": "4b2d1d5a"
   },
   "outputs": [],
   "source": [
    "# Evaluate each binary classifier\n",
    "results = {\n",
    "    'Class': [],\n",
    "    'Probs':[],\n",
    "    'Accuracy': [],\n",
    "    'F1 Score': [],\n",
    "    'Confusion Matrix': []\n",
    "}\n",
    "\n",
    "for i in range(3):  \n",
    "    predicted_class, probability = None     # predict on your test data\n",
    "    accuracy = None\n",
    "    f1 = None\n",
    "    cm = None\n",
    "    \n",
    "    results['Class'].append(i)\n",
    "    results['Probs'].append(probability)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['F1 Score'].append(f1)\n",
    "    results['Confusion Matrix'].append(cm)\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a4178-add4-4489-a483-32b16ae8818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.drop('Probs',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bd139-e747-492b-89fc-0e635a939f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi class evaluations.\n",
    "# Combine the probabilites of the classifiers calculated above and assign label of the classifier having the highest probability\n",
    "class_labels = ['Class 0: Most Likely Human', \n",
    "                'Class 1: Further Testing', \n",
    "                'Class 2: Most Likely Zombie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12664e-422d-4125-9c68-c90a644603bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the macro f1, accuracy and confusion matrix for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f0697",
   "metadata": {
    "id": "dc1f0697"
   },
   "source": [
    "# Part B: Use Scikit-learn  [10 Marks]\n",
    "\n",
    "In this part, use scikit-learn’s [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) implementation to train and test the logistic regression on the provided dataset.\n",
    "\n",
    "Use scikit-learn’s `accuracy_score` function to calculate the [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), F1 score and [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function to calculate confusion matrix on test set.\n",
    "\n",
    "Finally, plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7893b68",
   "metadata": {
    "id": "c7893b68"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b01b1669-f564-4393-9a9d-1a563aa62e35",
   "metadata": {},
   "source": [
    "# Part C: Are You a Zombie?  [5 marks]\n",
    "Use your multiclass classifier to predict whether you are a zombie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "33d64233-9b57-4995-8e00-220a75d4dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in these values (honestly)\n",
    "height = None               # Height in cm\n",
    "weight = None               # Weight in kg\n",
    "screen_time = None          # Screen time in hours per day\n",
    "junk_food_days = None       # Junk food consumption in days per week\n",
    "physical_activity = None    # Physical activity in hours per week\n",
    "task_completion = None      # Task completion on a scale (example range: 1-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "79ba3c22-e1e5-460f-b3c4-6ad578a8eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point = np.array([height, weight, screen_time, junk_food_days, physical_activity, task_completion])\n",
    "test_point = stdscaler.transform(test_point)  # transform using your standard scaler instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1379e7-1cfd-4b08-9c81-8698bb0aebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = {0: \"Human\", 1: \"Needs Further Testing\", 2: \"Zombie\"}\n",
    "probs=[]\n",
    "for i in range(3):  \n",
    "    y_pred_class, prob = classifiers[i].predict(test_point.reshape(1,-1))    \n",
    "    probs.append(prob)\n",
    "combined_probs = np.column_stack([p for p in probs])\n",
    "multi_class_pred = np.argmax(combined_probs, axis=1)\n",
    "print(\"Prediction:\", labels[multi_class_pred[0]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
