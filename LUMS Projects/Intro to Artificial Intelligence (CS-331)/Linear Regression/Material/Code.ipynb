{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlmMH0J0ZLoh"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrfmyAAtZLoi"
      },
      "source": [
        "# CS-331: Introduction to Artifical Intelligence\n",
        "\n",
        "## Linear Regression - 100 Marks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aErMzBFBZLoj"
      },
      "source": [
        "#### Name:\n",
        "#### Roll Number:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_EWrMv7ZLok"
      },
      "source": [
        " ### Instructions:\n",
        "- The aim of this assignment is to familiarize you with Uni-variate Linear Regression and Multi-variate Linear Regreesion..\n",
        "- You can only use Python programming language and Jupyter Notebooks.\n",
        "- Submit a zip file containing both the notebooks (.ipynb file) and their python files (.py file). Name the zip file `X_PA1`, where X is your rollnumber.\n",
        "- Rename the notebook `rollnumber_PA1.ipynb` by replacing `rollnumber` with your rollnumber. Same naming convention for the .py file\n",
        "- Please make sure all cells have been run.\n",
        "- The code MUST be done independently. Any plagiarism or copying of work from others will not be tolerated.\n",
        "- You are only supposed to write your code in the regions specified! Do NOT change any code that has already been written for you!\n",
        "- You CANNOT use the scikit learn library to implement any function, unless mentioned otherwise. The entire implementation should be your own!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y4S5jWEffpj"
      },
      "source": [
        "## Dataset Description\n",
        "\n",
        "The `temperatures.csv` dataset is designed for bias correction of next-day maximum and minimum air temperature forecasts produced by the Local Data Assimilation and Prediction System (LDAPS) operated by the Korea Meteorological Administration. It covers summer seasons from 2013 to 2017 in Seoul, South Korea.\n",
        "\n",
        "Dataset Summary:\n",
        "- **Feature Type:** Real\n",
        "- **Instances:** 7586\n",
        "- **Input Features:** 21 (including present-day temperature data, LDAPS model forecasts, and geographical information)\n",
        "- **Output:** Next-day maximum (Next_Tmax)\n",
        "\n",
        "\n",
        "We want to predict the next day temperature given the various features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ojNM1yeZLol"
      },
      "source": [
        "#### Libraries used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HACD7ar4ZLol"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsl2WoZpZLom"
      },
      "source": [
        "#### Import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmZ8RFF1ZLom"
      },
      "source": [
        "Here you will load the `temperatures.csv` file using <b>Pandas</b> library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1LNtOpkZLom"
      },
      "outputs": [],
      "source": [
        "# code here\n",
        "df = pd.read_csv('yourfile.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3IKuiq2aKjQ"
      },
      "source": [
        "## Part 1 - Univariate Regression (40 Marks)\n",
        "\n",
        "In this part, you will develop a univariate regression model using maximum temperature on present day `(Present_Tmax)` to predict the next day temperature `(Next_Tmax)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feature Extraction:\n",
        "\n",
        "Extract the `Present_Tmax` column as input and the `Next_Tmax` column as output from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Splitting the dataset\n",
        "Make a 70 30 split to divide the dataset into training and test dataset which will result in 4 variables: X_train, Y_train, X_test, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Nkj5VKZLon"
      },
      "source": [
        "### Learn the parameters\n",
        "In this part, you will fit the linear regression parameters $\\theta_0$ and $\\theta_1$ to the given dataset.\n",
        "\n",
        "The objective of linear regression is to minimize the cost function\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\left(\\hat {y}^{(i)} - y^{(i)}\\right)^2$$\n",
        "\n",
        "where the hypothesis $\\hat {y}^{(i)}$ is the predicted value for a given x and is given by the linear model and $m$ is the total number of datapoints\n",
        "$$ \\hat {y} =  h_\\theta(x) = \\theta_0 + \\theta_1 x$$\n",
        "\n",
        "The parameters of your model are the $\\theta_j$ values. These are\n",
        "the values you will adjust to minimize cost $J(\\theta)$. One way to do this is to\n",
        "use the batch gradient descent algorithm. In batch gradient descent, each\n",
        "iteration performs the update\n",
        "\n",
        "$$ \\theta_0 = \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat {y}^{(i)} - y^{(i)}\\right)$$\n",
        "\n",
        "$$ \\theta_1 = \\theta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat {y}^{(i)} - y^{(i)}\\right)x^{(i)}$$\n",
        "\n",
        "With each step of gradient descent, your parameters $\\theta_0$ and $\\theta_1$ come closer to the optimal values that will achieve the lowest cost $J(\\theta)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZb_MOi8ZLon"
      },
      "outputs": [],
      "source": [
        "def predict_SLR(): #you will have to decide the parameters for this function\n",
        "    #This function will return the predicted value of y based on the given parameters\n",
        "    return y_predicted\n",
        "\n",
        "def cost_SLR(): #you will have to decide the parameters for this function\n",
        "    return cost\n",
        "\n",
        "def gradient_descent_SLR(X,Y,alpha,epochs):\n",
        "    J = [] # this is a list of result of the cost function with each iteration\n",
        "    #you will need to start with arbitrary values of theta0 and theta1. Initialise those here\n",
        "\n",
        "    #theta0 = ?\n",
        "    #theta1 = ?\n",
        "    for epoch in range(epochs):\n",
        "        #this is the loop that will implement gradient descent. With each iteration, you will need to update the values of theta0 and theta1\n",
        "        #you will also have to calculate the loss with each updated value of theta0 and theta1\n",
        "\n",
        "    return theta0,theta1,J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmMuJePfZLon"
      },
      "source": [
        "#### Running Linear Regression\n",
        "\n",
        "Tune the hyperparameters (epochs and learning rate) to get the best fit model for linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzMJD_jcZLon"
      },
      "outputs": [],
      "source": [
        "#you will have to set these values to get the best fit model for linear regression\n",
        "n_epoch = 1000\n",
        "alpha = 0.1\n",
        "\n",
        "#this is the call to the gradient descent function\n",
        "#here X_train and Y_train are the arrays that you formed above using the dataset\n",
        "theta0, theta1, J = gradient_descent_SLR(X_train,y_train,alpha,n_epoch)\n",
        "print('Predicted theta0 = %.4f, theta1 = %.4f, cost = %.4f' % (theta0, theta1, J[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EnnrRhrZLon"
      },
      "source": [
        "#### Plotting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayn7gA8YZLon"
      },
      "source": [
        " This should output a graph with the original dataset points and the linear regression model using your learned values of theta0 and theta1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIc7wjYGZLon"
      },
      "outputs": [],
      "source": [
        "#DO NOT EDIT THIS CELL.\n",
        "y_pred_list_train = list()\n",
        "for x in X_train:\n",
        "    y_pred_list_train.append(predict_SLR(x, theta0, theta1))\n",
        "\n",
        "plt.plot(X_train, y_train, 'bo', ms=10, mec='k')\n",
        "plt.ylabel('Next_Tmax')\n",
        "plt.xlabel('Present_Tmax')\n",
        "plt.plot(X_train, y_pred_list_train, '-')\n",
        "plt.legend(['Training data', 'Linear regression'])\n",
        "plt.show()\n",
        "\n",
        "y_pred_list_test = list()\n",
        "for x in X_test:\n",
        "    y_pred_list_test.append(predict_SLR(x, theta0, theta1))\n",
        "\n",
        "plt.plot(X_test, y_test, 'ro', ms=10, mec='k')\n",
        "plt.ylabel('Next_Tmax')\n",
        "plt.xlabel('Present_Tmax')\n",
        "plt.plot(X_test, y_pred_list_test, '-')\n",
        "plt.legend(['Test data', 'Linear regression'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXHvDtIscVen"
      },
      "source": [
        "### Finding the Correlation\n",
        "Correlation is used to assess the association between features (input variables) and the target variable (output variable) in a dataset.\n",
        "\n",
        "* A positive correlation indicates a direct, linear relationship: as one variable increases, the other tends to increase as well.\n",
        "* A negative correlation indicates an inverse, linear relationship: as one variable increases, the other tends to decrease.\n",
        "* A correlation of 0 suggests no linear relationship between the variables.\n",
        "\n",
        "<br>\n",
        "Pick the top 5 features that have the best correlation with Next_Tmax and write them in the markdown block below the code block\n",
        "We will be using the following function to plot the correlation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7LJfBGsd4CQ"
      },
      "outputs": [],
      "source": [
        "#the features parameter is all the 22 columns other than the output feature in the dataset\n",
        "correlations = np.corrcoef(features, y_train, rowvar=False)[:21, -1]\n",
        "column_names = df.columns[:21]\n",
        "plt.figure(figsize=(18, 8))\n",
        "plt.bar(range(1, 22), correlations, tick_label=column_names, color='skyblue')\n",
        "plt.title('Correlation Coefficients between Features and Next_Tmax')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Correlation Coefficient')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLIPl45KnfPG"
      },
      "source": [
        "#### Top 5 features here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anXL4TGOjUME"
      },
      "source": [
        "### Improving Performance\n",
        "\n",
        "Try to improve performance of the model you have developed, i.e further reducing the cost, by selecting some other input feature instead of `Present_Tmax`, keeping the desired output as `Next_Tmax`\n",
        "\n",
        "* Write a comment comparing the previous and the new model i.e their features, hyperparameters\n",
        "* Plot the final value of cost function J for both models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOvP_ba-kw-p"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pItEGFHEZLoo"
      },
      "source": [
        "## Part 2: Multi-Variate Linear Regression (60 Marks)\n",
        "\n",
        "We will now use a similar concept as in the previous part to train a multivariate regression model on the same dataset. Instead of using just one input feature, we will now use the `Top-5 input features` that you have selected in the previous part. These features will be used to predict the next day temperature `(Next_Tmax)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feature Extraction:\n",
        "\n",
        "Extract the Top-5 features from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrDdm-SKZLoo"
      },
      "source": [
        "#### Splitting the dataset\n",
        "Make a `70 30` split to divide the dataset into training and test dataset which will result in 4 variables: X_train, Y_train, X_test, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nUH4sLdZLoo"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learn the parameters for Multivariate Regression\n",
        "\n",
        "In multivariate regression, we predict the output using multiple input features. The model has the form:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $\\hat{y}$ is the predicted value\n",
        "- $x_i$ represents each input feature\n",
        "- $\\theta_i$ are the parameters of our model\n",
        "\n",
        "The cost function for multivariate regression is an extension of the univariate case and is given by:\n",
        "\n",
        "$$\n",
        "J(\\Theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2\n",
        "$$\n",
        "\n",
        "Here, $\\Theta$ represents the parameter vector $(\\theta_0, \\theta_1, ..., \\theta_n)$, and $m$ is the number of training examples.\n",
        "\n",
        "To minimize the cost function $J(\\Theta)$, we use a method such as gradient descent, where each parameter $\\theta_j$ is updated as follows:\n",
        "\n",
        "$$\n",
        "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})x_j^{(i)}\n",
        "$$\n",
        "\n",
        "- $\\alpha$ is the learning rate\n",
        "- The summation is over all training examples\n",
        "\n",
        "\n",
        "With each iteration of gradient descent, the parameters $\\Theta$ come closer to the optimal values that minimize the cost function $J(\\Theta)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgGtMM1qZLop"
      },
      "source": [
        "#### Linear Regression:\n",
        "\n",
        "You will implement <b>Gradient Descent</b> to train the model on the data. You will be using Mean Square Error as the cost function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf-XVw5KZLop"
      },
      "outputs": [],
      "source": [
        "#You can add any helper functions that you may feel the need for\n",
        "\n",
        "def predict_MLR(): #decide on the variables for this function\n",
        "    #this function should return the predicted values based on the value of thetas\n",
        "    return y_pred\n",
        "\n",
        "def cost_MLR():#decide on the parameters for this function\n",
        "    #this function should return the value of the loss function\n",
        "    return cost\n",
        "\n",
        "#You will need to use a bias term as well\n",
        "def gradient_descent_MLR(X,Y,alpha,epochs):\n",
        "    J = []\n",
        "    #here you will need to initialise the values of thetas. Be mindful of the size you use for the thetas\n",
        "    #thetas = ?\n",
        "    for i in range(epochs):\n",
        "        #implement gradient descent here and update the values of thetas and the bias term\n",
        "\n",
        "    return thetas, J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGJm1TANZLop"
      },
      "source": [
        "#### Run the Regression\n",
        "\n",
        "For the specified number of epochs, run the regression and store the costs and corresponding thetas for each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goQUM5DSZLop"
      },
      "outputs": [],
      "source": [
        "#decide on an appropriate value of n_epoch and alpha\n",
        "# Return J for every epoch and Plot it against # of epochs.\n",
        "n_epoch = 1000\n",
        "learning_rate = 0.1\n",
        "thetas, J= gradient_descent_MLR(learning_rate, n_epoch)#this function needs two more parameters. You will need to add those based on your normalised data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FboicZmzZLop"
      },
      "source": [
        "### Visualizing the costs\n",
        "You can run the following cell to see how your costs change with each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpGvwsDMZLop"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(1,n_epoch),J[1:])\n",
        "plt.xlabel(\"number of epochs\")\n",
        "plt.ylabel(\"cost\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBK-5snjofZ5"
      },
      "source": [
        "### All input features\n",
        "\n",
        "Now, you will use `ALL` input features to predict `Next_Tmax`.\n",
        "\n",
        "Extract the features and run the following code block again. Make note of the differences between this model and the one that only used `5 features`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP_GaWBJpxA3"
      },
      "outputs": [],
      "source": [
        "#features =\n",
        "#output ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ6pk0Jmp6dD"
      },
      "source": [
        "Perform 70-30 split on the dataset again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-kUnj1RqHN-"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf7FfpqiqJwq"
      },
      "source": [
        "Call the gradient descent function again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abOv092AqGif"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8JYFy8sqOaC"
      },
      "source": [
        "Visualise the cost again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLNiso7SqSoF"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the final cost values for the previous model (with 5 features) and the new model (with all features)\n",
        "<br>\n",
        "\n",
        "(Hint: your costs are stored in a list so you would need to extract just the last one for both the models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#your plot here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o0NYBNRqbkX"
      },
      "source": [
        "### Analysis\n",
        "Choose the best model out of the 2 you have developed and conduct the following analysis:\n",
        "\n",
        "* Change the learning rates to `0.01`, `0.1`, and `1` and record the performance in terms of convergence plots ie. cost vs iterations for each learning rate\n",
        "\n",
        "* Change the train-test split ratios to `60-40`, `70-30` and `80-20` and record the performance in terms of convergence plots for each ratio i.e cost vs iterations for each split ratio\n",
        "\n",
        "* Change the number of iterations to `250`, `500`, `750` and `1000` and record the performance in terms of convergence plots for a range of iterations i.e cost vs range of iterations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Ex01SGqoCw"
      },
      "source": [
        "#### Effect of learning rate\n",
        "Use 70-30 split and number of iterations = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNS0P0H8qk3p"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the `final` value of the cost against the learning rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate_list = [0.01, 0.1, 1]\n",
        "cost_list = []  #you are to add the LAST value of the cost from your model to this list for each learning rate used\n",
        "\n",
        "plt.bar(learning_rate_list, cost_list, color='blue')\n",
        "plt.title('Effect of learning rate on cost')\n",
        "plt.xlabel('Learning rates')\n",
        "plt.ylabel('Cost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yyh0yqxqsEF"
      },
      "source": [
        "#### Effect of test-train split\n",
        "Use learning rate = 0.1 and iterations = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWy58D1kquwq"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the `final` value of the cost received for each split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_list = ['60-40', '70-30', '80-20']\n",
        "cost_list = []  #you are to add the LAST value of the cost from your model to this list for each split used\n",
        "\n",
        "plt.bar(split_list, cost_list, color='blue')\n",
        "plt.title('Effect of test-train split on cost')\n",
        "plt.xlabel('Split')\n",
        "plt.ylabel('Cost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGhHZk7hqvOe"
      },
      "source": [
        "#### Effect of number of iterations\n",
        "\n",
        "Use 70-30 split and learning rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKBqSydAqxif"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the `final` value of the cost against each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iter_list = [250, 500, 750, 1000] \n",
        "cost_list = []  #you are to add the LAST value of the cost from your model to this list for each iteration used\n",
        "\n",
        "plt.bar(iter_list, cost_list, color='blue')\n",
        "plt.title('Effect of number of iterations on cost')\n",
        "plt.xlabel('Number of Iterations')\n",
        "plt.ylabel('Cost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMK_fwjJrKzu"
      },
      "source": [
        "#### Document the effect of each change and give a concise explanation about it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFiuHrLsrpuu"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
